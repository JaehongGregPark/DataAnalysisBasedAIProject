AI2_day02
머신러닝의 학습방법 -> 아나콘다 설치 -> 주피터노트북 -> 붓꽃 데이터셋(분류)
1. 머신러닝
1) 지도학습
	문제와 정답을 모두 알려주고 학습시키는 방법
	반복학습을 통해 오류를 줄여나가면서 점차 정답에 가까워지는 방법
-분류 : 주어진 데이터가 어느 클래스에 속하는지 판별하는것
-회기 : 전달된 데이터를 바탕으로 값을 예상한다

2) 비지도학습
	값을 가르쳐주지 않고 예측하는 방법
-클러스터링(Clustering)
	전달된 데이터를 어떤 규칙에 따라서 나누는 것
	Kmeans
		몇개의 클러스터를 분할할지 사전에 정해둔 경우 추천
	스펙트럼 클러스터링(GMM)
		Kmeans로 분석되지 않은 경우 이용
		비선형적인 클러스터링 분석방법
	MeansShift, VGBGMM
		몇개의 클러스터를 분할할지 사전에 정할 수 없는 경우 추천
- 차원 축소(Dimensionality Reduction)
	데이터의 고차원 특성을 저차원으로 압축하여 데이터를 시각화하거나
	다른 분석작업에 활용하는데 사용

	주성분분석(PCA, Principal Component Analysis)
		데이터의 주성분을 추출하여 데이터의 차원을 줄이는 기법
	t-SNE
	LLE(Locally linear Embedding)

- 연관규칙학습(Association Rule Learning)
  	데이터세트에서 항목들 사이의 흥미로운 관계나 패턴을 찾는 작업

   	Apriori(알라희):빈발 항목 집합을 찾는데 사용

3) 강화학습
	주어진 환경과 상호작용하면서 보상을 최대화하기 위한 행동을 학습하는 방법
	에이전트(Agent) : 행동을 수행하는 주체
	환경(Environment): 에이전트가 상호작용하는 외부환경, 다양한 상태와 보상이 발생
	상태(State) : 에이전트와 환경의 상호작용을 통해 특정시점에서의 환경상태를 나타냄
	행동(Action): 에이전트가 특정상태에서 취할 수 있는 선택 가능한 행동의 집합
	보상(Reword): 에이전트가 특정행동을 수행한 결과 반는 보상신호

	Q-Learning
		에이전트가 환경과 상호작용하면서 초적의 Q-함수를 찾아가면서 최적으ㅢ 행동을 선택하도록 하는 학습방법
	SARSA 
 		상태-행동-보상-상태-행동 순서로 학습하는 방법	

2. 개발도구
	아나콘다(Anaconda)
	- 수학, 과학분야에서 사용되는 여러 패키지를 묶어놓은 파이썬 배포판
	- 데이터 관련 작업을 쉽게 시작할 수 있음
	- conda를 사용하여 패키지와 환경을 관리하면 사용할 다양한 라이브러리를 다룰때 발생할 수 있는 문제를 줄일수 있음
 	1) 설치
   		구글 > 아나콘다 검색 > download 링크 클릭
   		https://www.anaconda.com/download 
  		본인 pc 환경에 맞는 운영체제로 설치
		-> 설치진행
		-> Just Me 체크
		-> Destination Folder 기존경로
		-> Register Anaconda3 체크
		-> 아나콘다 네이케이터 잘열리는지 확인 (로그인x)
	2) 설치후 jupyter notebook실행
		anaconda prompt > 경로설정
		(base) 기본 경로 > D:
		(base) D: > cd D:/
		(base) D:
	3) 주피터노트북
		명령어를 작성할 수 있는 하나의 라인을 셀(cell)
		code : 셀의 내용을 명령어로 처리한다(파란색일 때 y키 입력)
		Markdown : 마크다운 문법을 사용하여 텍스트 굵게, 기울임, 제목크기 등의 서식을 지정할 수 있다(파란색일때 m키 입력)
		Raw NBConvert : 셀에 입력된 내용을 그대로 출력한다(파란색일 때 r키 입력)
   		Heading : 헤더타입의 서식으로 셀의 내용을 변경한다
		
		셀실행 단축기 : 
			ctrl + enter(그셀만 실행)
			alt + enter (셀 실행후 다음셀 삽입)
		셀 나누기
			ctrl + shift + -
		아래셀 합치기
			shift + m
		하단에 셀 삽입 : 셀을 선택한 상태에서 b
		상단에 셀 삽입 : 셀을 선택한 상태에서 a
   		하단의 셀 선택 : 방향키 or 셀을 선택한 상태에서 j
   		상단의 셀 선택 : 방향키 or 셀을 선택한 상태에서 k
		
		셀 삭제 : 셀선택한 상태에서 dd
		셀 잘라내기 : 셀선택한 상태에서 x
		셀 복사하기 : 셀선택한 상태에서 c
		셀 상단에 붙이기 : 셀 선택한 상태에서 shift + v
		셀 하단에 붙이기 : 셀 선택한 상태에서 v
		
		파란색 테두리 => 명령모드 - 셀(라인,행)에 대해 명령을 내릴때
		초록색 테두리 => 편집모드 - 코드를 입력하거나 마크다운 입력, 편집할 때
		
		명령모드 -> 편집모드 : enter
		편집모드 -> 명령모드 : esc

3. 분류 알고리즘
1)KNN(K-Nearest Neighbors Algorithm) : K-최근접 이웃 알고리즘
	예측하려는 데이터 x가 주어지면 기존 데이터 속성중 속성이 비슷한 K개의 이웃을 먼저 찾는 알고리즘
KNeighborsClassifier 클래스 속성값
class : 모델이 학습한 클래스 레이블(정답)의 배열
metric: 모델에서 사용하는 실제 거리 측정방법
	(1) 맨하탄거리(Manhattan Distance)
		두데이터 포인트간의 차이를 모든 차원에서 절대값으로 계산하고 모두 합한 값을 거리로 사용
	(2) 유클리드거리(Euclidean Distance)
		두 데이터 포인트간의 차이를 모든 차원에서 제곱한 후 모두 합한 값을 제곱근으로 계산값 거리로 사용
	(3) 맨해튼거리(Chebyshev Distance)
		두데이터 포인트 간의 차이를 모든 차원에서 절대값으로 계산하고 가장 큰 값을 거리로 사용
	(4) 미스테이로비치 거리(Minkowsikei Distance)
		두 데이터 포인트간의 각 차원의 차이를 p승한 값들의 합을 p번째 루트로 계산한 값을 거리로 사용
		      	(p = 1 맨하탄거리, p = 2 유클리드 거리 동일) 
metric_params
	모델에서 사용하는 실제거리 측정방법의 매개 변수
n_features_in 
	모델이 학습한 입력 데이터의 특징(feature)수
n_neighbors	
	모델이 사용하는 이웃의 개수
outputs_2d
	모델이 다중 분류 문제를 다루는 경우 이값이 True이면 모델의 예측 결과가 2차원 배열로 반환
weights      
	모델에서 사용하는 이웃 가중치(weight)	
	
2) SVM(Support Vector Classfication)
	데이터 셋의 각 feature(열) 벡터들이 고유의 축을 갖는 벡터공간을 이룬다고 가정
	모든 데이터를 벡터내의 좌표에 점으로 표기하고 각 데이터 속하는 목표 클래스별로
	군집을 이룬다고 생각함
	각 군집까지의 거리를 최대한 멀리 유지하는 경계면을 찾고 군집을 확연하게 구분할 수 있음
	=> 1.0으로 출력됨 100%를 의미
	과적합 문제가 있음 => 모델의 복잡도가 높을 때 데이터셋에 지나치게 적합(fit)되어서 
	학습 데이터 셋에서는 높은 정확도를 보이지만 새로운 데이터셋에서는 낮은 정확도를 보이는 현상
SVM매개변수
C   	: 오차 허용 범위를 조절
kernel  : 데이터를 고차원으로 매핑하는 커널 함수
gamma   : 커널의 영향 범위 제어		

3) 로지스틱 회귀(Logistic Regression)
	선형회귀와 비슷한 모델을 사용하지만 출력값이 이항 분류일 때 사용됨
	입력값의 가중치의 합을 구하고 시그모이드 함수에 적용해서 0과 1사이의 값을 출력함
	* 이항분류(binary classification)
		두개의 클래스로 분류하난 분제를 의미함
		양성/음성, 참/거짓, 사기/정상 등 두 가지 범주 중에서 하나로 분류하는 문제를 의미함

4) 의사결정나무(Decision Tree)
	데이터의 피쳐(특징)들을 이용해서 분류 규칙을 만드는 분류 모델
	학습 데이터셋을 이용하여 분류 규칙을 만들어 내는 과정을 거침 -> 입력 데이터는 각 특징을 이용하여
	데이터를 분할 -> 분할한 데이터의 지니불순도를 이용하여 분할의 효율성을 평가한다
	* 지니불순도(Gini impurity)
      		머신러닝과 결정트리 알고리즘에서 사용하는 개념
      		데이터 집합을 불순도를 측정하는 지표
      		0~1까지 값을 가지며 값이 작을 수록 순수도가 높은 하위집합을 의미함

-------------------------------------------------------------------------------------
4. 훈련 데이터셋과 테스트 테이터 셋
	훈련데이터 세트(셋) : 머신러닝 알고리즘의 학습을 위해 사용
		데이터 속성과 결정값(라벨) 모두 가지고 있음
		학습 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성과 결정값의 패턴을 인지하고 학습
	테스트데이터 세트(셋) : 테스트 데이터 세트에서 학습된 머신러닝 알고리즘
		테스트 데이터에는 속성 데이터만 포함
		머신러닝 알고리즘은 제공된 데이터를 기반으로 결정값을 예측
		테스트 데이터는 학습 데이터와 별도 데이터 셋으로 제공되어야 함

5.iris 데이터셋 확인
'data' 		데이터셋의 특징(feature) 데이터를 담고 있는 배열 
                각행은 개별 데이터 포인터를 나타내며, 각열을 해당 데이터 포인트의 특징을 나타냄
'target'	데이터셋의 타겟(target)데이터를 담고 있는 배열
		각 원소는 해당 데이터 포인트의 클래스(레이블,라벨)을 나타냄
'frame'		데이터와 타겟을 담고 있는 판다스의 데이터 프레임
		csv파일로부터 로드된 경우에만 사용됨
'target_names'	타겟클래스(레이블)의 이름을 담고 있는 배열 또는 리스트
'DESCR'		테이터셋에 대한 설명을 담고 있는 문자열
		출처,특징들의 의미, 타겟클래스의 의미에 대한 정보
'feature_names'	각특징의 이름을 담고 잇는 배열(리스트)
		주로 data 배열의 각열에 해당하는 특징들의 이름을 나타냄
'filename'      데이터셋이 로드된 파일의 경로를 나타내는 문자열
'filename'      데이터셋이 로드된 파일의 경로를 나타내는 문자열(string)
         	주로 로컬 파일시스템에서 데이터셋을 로드한 경우에만 사용됨
'data_module'   데이터셋이 속한 모듈의 이름을 나타내는 문자열
         	사이킷런의 내장 데이터셋 sklearn.datasets모듈에 속해있음

6.seaborn
	파이썬 데이터 시각화 라이브러리
	통계적 그래프를 생성하기 위한 함수와 스타일을 제공함
	
	import seabon as sns
	sns.displot(data = df, x='x축에 들어갈 값', kind='그래프 종류')

	.displot()	: 데이터 분포를 시각화 하는 함수
	x 		: x축에 어떤 열의 데이터를 사용할 것인지 작성
	kind 		: 어떤 방법으로 그래프를 그릴 것이지 작성
	data		: 사각화할 데이터가 담긴 데이터 프레임을 지정
kind의 종류
   	.histplot()   : 히스토그램(데이터 분포를 막대그래프로 표현)
   	.scatterplot()   : 산점도(두 변수 간의 관계를 표현)
   	.lineplot()   : 선그래프(시간/순서 등에 따른 변화를 표현)
   	.boxplot()   : 상자 그래프(데이터의 중앙값, 분포, 아웃라이어-이상치 등을 표현)
   	.pairplot()   : 데이터 프레임의 열들을 쌍으로 묶어서 그래프 생성
   	.heatmap()   : 열과 행에 대한 정보를 히트맵 형태로 표현   