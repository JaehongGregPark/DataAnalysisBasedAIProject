AI2_day04
교차검증
1.교차검증
	학습 데이터셋을 학습 데이터셋과 검증 데이터셋으로 분리
	학습 데이터(train) : 학습을 위한 데이터
	검증 데이터(validation) : 학습 모델의 성능을 일차 평가
	평가 데이터(test):모든 학습/검증 과정이 완료된 후 최종적으로 성능 평가
1) K-폴드 교차검증(K-Fold Cross Validation)
	K개의 폴드 세트에 k번의 학습과 검증 평가 반복 수행

K-폴드 교차 검증의 문제점 : 단순히 무작위로 데이터를 분할하기 때문에
	각 폴드에서의 클래스 비율이 전체 데이터셋의 클래스 비율과 다르게
	나타나는 문제 발생 가능성이 있음
2) Stratified K-Fold
	기존의 K-Fold 교차 검증의 문제점을 해결하기 위해 사용
   	분류 문제에서 클래스별로 균형을 유지하면서 데이터를 분할하는 기법
   	각 폴드에서 클래스 비율이 원래 데이터셋과 유사하도록 보장하여
   	모델의 성능평가를 더 정확하게 수행할 수 있음
과정
	- 클래스 분포 확인: 데이터셋의 클래스 분포를 확인
		분류문제에서는 클래스 레이블을 가지고 있으며 각 클래스의 속하는 샘플의 수를 계산함
	- 폴드 생성 : 데이터셋을 K개의 폴드로 나눔
		각 폴드에서는 원래 데이터셋의 클래스 비율과 유사한 비율로 클래스 샘슬이 포함되도록 분할함
	- 모델학습과 평가 : k개의 폴드중 하나를 선택하여 테스트 셋으로 사용하고
		나머지 k-1개의 폴드를 학습 세트로 사용함
		선택된 모델을 학습세트로 학습시키고 테스트세트로 평가하여 모델의 성능측정
   	- k번 반복 : 1~3 과정을 k번 반복, 각각의 폴드가 한번씩 테스트 세트로 사용되도록
      		모델을 평가 
3) Cross_val_score()
	교차검증을 편하게 할 수 있도록 함
	사이킷런 라이브러리에서 제공하는 함수로 교차검증을 수행해서 모델의 성능을 평가하는데 사용됨
	지정한 모델과 데이터셋, 교차검증을 수행하는 방법을 매개변수로 받아 교차검증의 정확도를 반환함
매개변수
	estimator : 분류 알고리즘 클래스 Classifier 또는 회귀 알고리즘 Regressor
	features : 특성 데이터 셋
	label : 레이블데이터셋
	scoring : 예측 성능 평가지표
		분류 => 정확도(accuracy), 정밀도(precision), 재현율(recall), F1-Score
      		회귀 => 평균제곱오차(MSE), 결정계수(R2 Score)
   	cv   : 교차 검증 폴드 수
2. 오버피팅과 언더피팅
1)오버피팅(overfitting)
	학습데이터에 대해 과하게 학습된 상황
	학습데이터 이외에 데이터에 대해선 모델이 잘 동작하지 못한다(학습데이터가 부족한경우, 데이터 특성에 비해 모델이 너무 복잡한 경우에 발생)
오버피팅 해결방안
	- 모델이 학습데이터에 비해 과하게 복잡해 지지 않도록 layer의 갯수를 줄이는등 모델을 간단하게 만든다
	- L1/L2 정규화
	- 학습데이터 늘리기
2)언더피팅(underfitting)
	과소적합은 이미 있는 학습데이터 세트도 학습을 하지 못한 상태를 의미
	(학습 반복횟수가 너무 적은 경우, 데이터의 특성에 비해 모델이 너무 간단한 경우, 데이터의 양이 적은 경우)	