day06
텐서플로우 -> cnn -> 프로젝트

https://colab.research.google.com/drive/1GNWqzHL0hGKv85kV7TtUA7KPfQ7vqXo4?usp=sharing
https://colab.research.google.com/drive/1iB3b-G_tlNMl7z9bpRpaaPqnAM583MdV?usp=sharing

1. 텐서플로우(TenseorFlow)
	구글에서 개발한 오픈소스 머신러닝 프레임워크
	- 그래프 기반 계산
	- 다양한 플랫폼 지원
	- 자동 미분
	- 높은 수준의 API(케라스 API를 내장)

1) 텐서(Tensor)
	텐서 mulit-dimentsional array를 나타내는 말
	텐서 플로우의 기본 데이터 타입

2) 변수 텐서(Variable Tensor)
	가변성(Mutable)
	생성 후 내부 값을 수정 가능하고 모델의 가중치처럼 훈련중 업데이트 되어야하는
	값들을 나타내기 위해 사용
	tf.Variable() 클래스를 사용하여 생성
	초기값과 데이터 타입을 지정할 수 있음
	변수 텐서는 .assign() 메소드를 통해 값을 변경가능함

	import tensorflow as tf
	tensor1 = tf.Variable(값, dtype=tf.int32)
	tensor1.assign(변경할 값)

2) 상수 텐서(Constant Tensor)
	불변성(Immutable)
	한 번 생성되면 내부 값이 변경될 수 없음(값을 수정하거나 할당할 수 없음)
	모델의 하이퍼파라미터나 고정된 상수 값을 나타내기 위해 사용함
	tf.constant() 함수를 사용하여 생성, 데이터 타입과 함께 값을 지정 가능함

	import tensorflow as tf
	tensor2 = tf.constant(3.14, dtype=tf.float32)
	
3) 넘파이 배열을 텐서 변환
	변수 = tf.convert_to_tensor(넘파이배열)

   리스트를 텐서로 변환
	변수 = tf.convert_to_tensor(리스트)

4) 텐서를 넘파이 배열로 변환
	변수.numpy()

5) 텐서플로우 함수
	tf.constant 	상수 텐서를 생성하는 함수, 주어진 값을 가지고 텐서를 생성
	tf.Variable	변수 텐서를 생성하는 함수, 학습 가능한 변수를 만들 때 사용
	tf.add		두 텐서를 더하는 함수
	tf.matmul	두 텐서를 행렬 곱셈하는 함수
	tf.zeros((행, 열))	모든 요소가 0인 텐서를 생성하는 함수
	tf.ones((행, 열))		모든 요소가 1인 텐서를 생성하는 함수
	tf.fill((행, 열), 값)	주어진 모든 원소를 채운 텐서를 생성하는 함수
		ex) tf.fill((2, 3), 5) => 모든 원소가 5로 채워진 2x3 텐서 생성
	
6) 텐서의 속성
	차원(Dimension) 또는 랭크(Rank) : 배열의 축의 개수
		스칼라 차원 0, 1차원 배열 차원1, 2차원 배열 차원2
	크기(shape)	: 각 차원의 요소 수
		2 x 3  => (2, 3)인 텐서
	데이터타입(data type) : 원소들의 특정 데이터 타입
	텐서플로우 Eagerd Execution : 2.0이상 버전 기본적으로 적용됨
		텐서 연산이 즉시 실행되고 결과를 바로 확인할 수 있도록 해주는 기능
	디바이스(device)	: 텐서가 어떤 장치에서 저장되는지를 나타냄(CPU, GPU 등)
	텐서연산(operation) : 텐서 곱셈, 덧셈, 행렬곱셈, 활성화함수 적용 등이 텐서연산에 해당됨





2. CNN, RNN, GAN
1) CNN(Convolutional Neural Network)
	주로 이미지 처리에 사용되는 딥러닝 모델
	지역적인 패턴 및 공간적인 구조를 인식하기 위해 컨볼루션 레이어(Convolutional Layer)를 사용한다
	이미지의 특징을 추출하기 위해 입력데이터에 여러 필터를 적용하고, 이미지를 잘 이해할 수 있도록한다
	CNN은 합성곱(Convolution), 활성화함수(Activation), 풀링(Pooling) 계층으로 이루어져잇다
	
2) RNN(Recurrent Neural Network)
	순차적인 데이터 처리에 사용되는 딥러닝 모델
	순환구조를 가지며, 이전 시간 단계의 출력을 현재시간 단계의 입력으로 사용한다
	ex) 시계열 데이터, 자연어 등

3) GAN(Generative Adversarial Network)
	생성모델 중 하나
	두 개의 신경망인 생성자(Generator)와 판별자(Discriminator)가 서로 대립하며 경쟁하는 구조
	생성자는 진짜와 구별할 수 없는 가짜 데이터를 생성하고자 노력하고 
	판별자는 진짜와 가짜를 더 정확하게 구별하게 된다
	주로 이미지생성, 이미지변환, 이미지 편집 등에서 사용됨


3. MNIST 데이터셋
	숫자 손글씨가 있는 작은 이미지 데이터셋
	손으로 쓴 숫자 이미지를 보고 해당 숫자를 인식하는 분류문제
	
- CNN을 사용하여 MNIST 데이터셋을 학습하는 과정
	(1) 데이터 셋 불러오기(학습, 테스트 용으로 데이터 분리)
	(2) 모델 구성(CNN모델 구성)-컨볼루션 레이어, 풀링레이어, 완전연결레이어 등을 포함
	(3) 모델 컴파일 - 모델 컴파일, 손실함수와 최적화 알고리즘을 선택
	(4) 모델 학습
	(5) 모델 평가

+) 모델 구성
Sequential 모델 생성
	Conv2D 레이어 추가 : 컨볼루션 연산 수행
Conv2D(32, kernel_size = (5, 5), strides=(1, 1), padding="same", activation="relu", input_shape=input_shape)
	32 : 출력 필터의 수(이 레이어에서 생성할 특징 맵의 개수)
	kernel_size = (5, 5) : 컨볼루션 커널의 크기(5x5 크기의 커널을 사용하여 입력이미지와 합성곱 수행)
	strides = (1, 1) : 컨볼루션 연산을 수행할 때 커널의 이미지 위로 이동하는 간격을 의미
		커널이 이미지를 한 픽셀씩 이동하면서 합성곱을 수행
	padding = "same" : 패딩 방법을 설정, same으로 설정하면 출력 특징맵의 크기를 입력이미지와 동일하게
		유지하도록 패딩을 추가
	activation = "relu" : 활성화 함수를 설정, 음수입력 0, 양수입력은 그대로 반환
		비선형성을 추가
	input_shape = input_shape : 입력이미지 모양을 지정 (28, 28, 1) 크기의 이미지가 입력
		(너비, 높이, 채널수) 채널수가 1이면 흑백이미지를 의미

model.add(MaxPooling2D(pool_size=(2,2), strides = (2, 2)))
	MaxPooling2D 레이어를 추가하여 풀링을 수행한다
	
pool_size=(2,2) : 풀링 윈도우의 크기를 지정
	입력 특징맵 위를 슬라이딩하여 최대 풀링 연산을 수행함
	(2, 2) 크기의 풀링 윈도우를 사용하여 특징 맵을 2x2영역으로 나누고 각 영역에서 가장 큰값을 선택하여
	다운샘플링을 함

strides = (2, 2) : 풀링 연산을 수행할 때 풀링 윈도우가 입력 위를 이동하는 간격
	(2, 2)로 설정되어 있으므로 풀링 윈도우가 입력을 2픽셀씩 이동하면서 최대 풀링을 수행함
	출력 특징 맵의 크기가 입력 특징 맵의 크기의 절반으로 줄어들게 됨

=> 풀링레이어는 입력 이미지의 공간 차원을 줄이고 위치 불변성을 추가하여 모델이 작은 변환에 덜 민감하게 만든다
	모델이 특징을 학습하는데 도움이 되고 계산량을 줄여 연산 속도를 향상시킬 수 있다

model.add(Flatten())
	Flatten 레이어를 추가하여 다차원 데이터를 1차원으로 변환(1차원 벡터로 변환하여 출력)
	컨볼루션 레이어와 완전연결레이어 사이에 위치하여 다차원의 특징 맵을 1차원으로 펼쳐주는 역할을 한다

	(4, 4, 64) -> 1024

model.add(Dense(1000, activation="relu"))
	완전 연결 레이어
	
1000	: 뉴런의 수, 이전 층의 모든 입력과 연결되어있으며, 각 연결은 가중치로 가지고 있다
activation = "relu" : 활성화 함수
	
	이전의 컨볼루션 레이어에서 추출된 특징을 입력으로 받고, 입력데이터와 클래스간의 복잡한 관계를 학습
	완전연결층은 입력데이터를 다양한 방법으로 조합하여 최종 출력을 생성하므로 모델이 더 복잡한 패턴을
	학습 할 수 있게 함

----------------------------------------------------------
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_6 (Conv2D)           (None, 28, 28, 32)        832       32개의 5x5크기의 필터를 적용하여 입력이미지를 합성곱									출력형태(높이, 너비, 채널수)로 이루어진 3차원 텐서	
                                                                 
 max_pooling2d_6 (MaxPoolin  (None, 14, 14, 32)        0         2x2 크기의 필터를 적용하여 입력 이미지를 합성곱
 g2D)                                                            
                                                                 
 conv2d_7 (Conv2D)           (None, 14, 14, 64)        8256      64개의 2x2크기의 필터를 적용하여 입력이미지를 합성곱
                                                                 
 max_pooling2d_7 (MaxPoolin  (None, 7, 7, 64)          0         2x2크기의 풀링 윈도우를 사용하여 
								 입력이미지를 다운샘플링
 g2D)                                                            
                                                                 
 dropout_4 (Dropout)         (None, 7, 7, 64)          0         학습중에 무작위로 일부 뉴런을 비활성화
								 과적합을 방지하기 위함
                                                                 
 flatten_3 (Flatten)         (None, 3136)              0         다차원의 입력을 1차원으로 평탄화(완전연결층으로 전달)
                                                                 
 dense_6 (Dense)             (None, 1000)              3137000   1000개의 뉴런을 가진 완전연결층(ReLU 활성화함수)
                                                                 	
 dropout_5 (Dropout)         (None, 1000)              0         드롭아웃을 적용하여 과적합을 방지
                                                                 	
 dense_7 (Dense)             (None, 10)                10010     10개의 뉴런을 가진 완전연결층(소프트맥스를 사용)
								  각 클래스에 대한 확률 출력함
                                                                 
=================================================================
Total params: 3156098 (12.04 MB)				모델의 총 학습가능한 파라미터 수	
Trainable params: 3156098 (12.04 MB)				실제로 학습되는 파라미터 수
Non-trainable params: 0 (0.00 Byte)				학습되지 않는 파라미터 수(모델 내부의 고정된 파라미터를 								나타냄)
_________________________________________________________________






















